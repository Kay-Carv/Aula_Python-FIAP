# -*- coding: utf-8 -*-
"""analiseDeDados-RedesNeuraisParaClassificacao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vhv5d-xRov1F6_bI4PwK-coJSQQhdulf

# TEMA DA AULA: Analise de dados e Introdução de Redes Neurais

"""
 # %%
import pandas as pd
import matplotlib.pyplot as plt

#%%
dados = pd.read_csv(r'./manutencao_preditiva.csv')
dados.info()

dados

x = dados['UDI']
y1 = dados['Temperatura Ar [K]']
y2 = dados['Temperatura Processo [K]']

plt.plot(x, y1, x, y2)
plt.xlabel('Amostra')
plt.ylabel('Temperatura [k]')
plt.legend(['Ar', 'Processo'])
plt.legend(['Ar', 'Processo'])

# Fazendo com que seja possivel visualizar os dados e os valores de falhas

x = dados['UDI']
y1 = dados['Torque [Nm]']

plt.scatter(x, y1)  #Tipo de gráfico
plt.xlabel('Amostra')
plt.ylabel('Torque [Nm]')
plt.legend(['Torque'])
plt.show()

x = dados['UDI']
y1 = dados['Temperatura Ar [K]']
y2 = dados['Temperatura Processo [K]']
y3 = dados['Velocidade Rotacao [rpm]']
y4 = dados['Torque [Nm]']

plt.plot(x, y1, x, y2, x, y3, x, y4)
plt.xlabel('Amostra')
plt.ylabel('Temperatura [k]')
plt.legend(['Ar', 'Processo', 'Vel. rotação', 'Torque'])
plt.show()

#   Não é possível visualizar devido a quantidade muito alta de cada variavel, onde uma acaba achatando a outro
# Logo é preciso Normalizalas com MIM e MAX valores

"""# Normalização de dados

"""

"""Um dos caminhos, mas não muito prático"""

# Logo é preciso Normalizalas com MIM e MAX valores
#  X.norm = X - X.min / X.max - X.min

y_tem_ar_min = dados['Temperatura Ar [K]'].min()
y_tem_ar_max = dados['Temperatura Ar [K]'].max()

y_tem_proc_min = dados['Temperatura Processo [K]'].min()
y_tem_proc_max = dados['Temperatura Processo [K]'].max()

temp_ar_nomralizado = (dados['Temperatura Ar [K]'] - y_tem_ar_min) / (y_tem_ar_max - y_tem_ar_min)
temp_proc_nomralizado = (dados['Temperatura Processo [K]'] - y_tem_proc_min) / (y_tem_proc_max)

temp_ar_nomralizado


#   Não é possível visualizar devido a quantidade muito alta de cada variavel, onde uma acaba achatando a outro
# Logo é preciso Normalizalas com MIM e MAX valores

# Função para normalização dos dados

def normaliza_dados (df, colunas):
  df_normalizado = dados.copy() # Copia os dados para uma nova variavel
  for coluna in colunas:
    # Max e Min valor de uma coluna
    min_val = df[coluna].min()
    max_val = df[coluna].max()

  # Aplicar a normalização

    df_normalizado[coluna] = (df[coluna] - min_val) / (max_val - min_val)

    return df_normalizado


df_normalizado1 = normaliza_dados(dados, ['Temperatura Ar [K]'])
df_normalizado2 = normaliza_dados(dados, ['Temperatura Processo [K]'])
df_normalizado3 = normaliza_dados(dados, ['Velocidade Rotacao [rpm]'])
df_normalizado4 = normaliza_dados(dados, ['Torque [Nm]'])

# Uso das variaveis normalizadas para criar o gráfico

amostras = df_normalizado1['UDI']

df_temp_ar_norm = df_normalizado1['Temperatura Ar [K]']
df_temp_proc_norm = df_normalizado2['Temperatura Processo [K]']
df_vel_rotacao_norm = df_normalizado3['Velocidade Rotacao [rpm]']
df_torque_norm = df_normalizado4['Torque [Nm]']

# Criar gráfico

plt.plot(amostras, df_temp_ar_norm, amostras, df_temp_proc_norm, amostras, df_vel_rotacao_norm, amostras, df_torque_norm)
plt.show()

# Aqui seria mais interessante separar os gráficos para poder visualiza-los, já que mesmo após a normalização não é possivel ver todos os 4

# %%

"""# Uso de redes neurais artificiais"""

# MLP (Multilayer Percptron)
# Inputs e outputs


# pip install scikit-learn
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier

x = dados[['Temperatura Ar [K]', 'Temperatura Processo [K]', 'Velocidade Rotacao [rpm]', 'Torque [Nm]']]
y = dados['Tipo da Falha']

# Separa os dados para treino e teste

xtreino, xteste, ytreino, yteste = train_test_split(x, y, test_size = 0.3 ) # (entrada, saída, porcentagem dos dados que serão usados para treino e para teste)

# Parametros do modelo MPL

mlp = MLPClassifier(hidden_layer_sizes=(100), max_iter = 100, activation='relu', solver='adam', verbose=True)  # Aqui a gente pode mudar a quantia de neuronios/parametro da rede neural para tentar aumentar a acurracy
#   ...hidden_layer_sizes=({qtd_neuronios}), max_iter = {qtd_ÉPOCAS}, activation='relu'...
mlp.fit(xtreino, ytreino)

# Teste de visualização

xtreino

# Calculando os valore de loss

loss_values = mlp.loss_curve_


plt.figure(figsize=(6, 4))
plt.plot(loss_values, label='Erro (loss)', color='green')
plt.xlabel('Épocas')
plt.ylabel('Erro')
plt.grid(True)
plt.legend()
plt.show()

# De acordo com o gráfico gerado é possível entender se a rede neural aprendeu ou não

# Predições para os dados de treino e teste

y_predicao_treino = mlp.predict(xtreino)
y_predicao_teste = mlp.predict(xteste)

y_predicao_treino
# y_predicao_treino

# Nesse caso temos testes de cada uma, retornou sem falhas

"""# Métricas de desempenho"""

from sklearn.metrics import accuracy_score

# Métrica de acurácia

acuracia_treino = accuracy_score(ytreino, y_predicao_treino)
acuracia_teste = accuracy_score(yteste, y_predicao_teste)

print(f'Acurácia treino: {acuracia_treino}')
print(f'Acurácia teste: {acuracia_teste}')

# Considerando 4 variaveis e 7 mil para treino com 5 tipos de falhas a Rede neural conseguiu em torno de 96% de acertividade para estimar os erros/falhas de cada parametro

"""# Código completo"""

import pandas as pd
import matplotlib.pyplot as plt

dados = pd.read_csv(r'./manutencao_preditiva.csv')


# Calculando os valore de loss

loss_values = mlp.loss_curve_


plt.figure(figsize=(6, 4))
plt.plot(loss_values, label='Erro (loss)', color='green')
plt.xlabel('Épocas')
plt.ylabel('Erro')
plt.grid(True)
plt.legend()
plt.show()

# Predições para os dados de treino e teste

y_predicao_treino = mlp.predict(xtreino)
y_predicao_teste = mlp.predict(xteste)

from sklearn.metrics import accuracy_score

# Métrica de acurácia

acuracia_treino = accuracy_score(ytreino, y_predicao_treino)
acuracia_teste = accuracy_score(yteste, y_predicao_teste)

print(f'Acurácia treino: {acuracia_treino}')
print(f'Acurácia teste: {acuracia_teste}')
# %%
